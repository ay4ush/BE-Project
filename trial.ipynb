{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3be83c4-e663-40c9-8b97-df9dbe803e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ef0395-37fc-4849-b80d-ae290a097344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551c1698-504b-4982-b6da-bf9f7043b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = 'images/validation'\n",
    "TRAIN_DIR = 'images/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021f1614-8841-459d-b95d-68dce7555515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdir(dir):\n",
    "    image_path = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            image_path.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label,\"completed\")\n",
    "    return image_path,labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5b3f819-2043-4f79-9eb7-b9ed2c90e1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "\n",
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "                               images    labels\n",
      "0            images/train\\angry\\0.jpg     angry\n",
      "1            images/train\\angry\\1.jpg     angry\n",
      "2           images/train\\angry\\10.jpg     angry\n",
      "3        images/train\\angry\\10002.jpg     angry\n",
      "4        images/train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images/train\\surprise\\9969.jpg  surprise\n",
      "28817  images/train\\surprise\\9985.jpg  surprise\n",
      "28818  images/train\\surprise\\9990.jpg  surprise\n",
      "28819  images/train\\surprise\\9992.jpg  surprise\n",
      "28820  images/train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n",
      "\n",
      "                                   images    labels\n",
      "0       images/validation\\angry\\10052.jpg     angry\n",
      "1       images/validation\\angry\\10065.jpg     angry\n",
      "2       images/validation\\angry\\10079.jpg     angry\n",
      "3       images/validation\\angry\\10095.jpg     angry\n",
      "4       images/validation\\angry\\10121.jpg     angry\n",
      "...                                   ...       ...\n",
      "7061  images/validation\\surprise\\9806.jpg  surprise\n",
      "7062  images/validation\\surprise\\9830.jpg  surprise\n",
      "7063  images/validation\\surprise\\9853.jpg  surprise\n",
      "7064  images/validation\\surprise\\9878.jpg  surprise\n",
      "7065   images/validation\\surprise\\993.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['images'],train['labels'] = createdir(TRAIN_DIR)\n",
    "print()\n",
    "test = pd.DataFrame()\n",
    "test['images'], test['labels'] = createdir(TEST_DIR)\n",
    "print(train)\n",
    "print()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f90c7842-634b-428e-85e8-821954e2c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(images):\n",
    "    features = []\n",
    "    for img in tqdm(images):\n",
    "        image = load_img(img,grayscale=True)\n",
    "        image = np.array(image)\n",
    "        features.append(image)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features),48,48,1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6fc7d0-a3bc-494b-90ca-f4e50fce5b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8294f7ce19e44a49a7260f026cb3e6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_features = feature_extraction(train['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eefc4470-9d89-4fd4-943c-d967c8f1d77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4173c27730c74ce7ac94f9d5fd72b0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = feature_extraction(test['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a87a1af-c4db-4bad-9a2c-5042bd917d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c70bb60-abac-4744-8f53-37a75ea4cac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e194b59-a0d8-4564-84e2-8113cd65896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['labels'])\n",
    "y_test = le.transform(test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01c75da0-9c6b-4622-beee-560c39372d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes=7)\n",
    "y_test = to_categorical(y_test,num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbba2772-23c2-4c87-b4b6-3e53453ee1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128,kernel_size=(3,3),activation='relu',input_shape = (48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(7,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70ad1ec2-f937-4e19-be98-5775206e4b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6d3fe-1611-417b-9569-8d829f4d6feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "226/226 [==============================] - 173s 766ms/step - loss: 1.7793 - accuracy: 0.2581 - val_loss: 1.7440 - val_accuracy: 0.2978\n",
      "Epoch 2/100\n",
      "226/226 [==============================] - 180s 797ms/step - loss: 1.6786 - accuracy: 0.3209 - val_loss: 1.5290 - val_accuracy: 0.3929\n",
      "Epoch 3/100\n",
      "226/226 [==============================] - 186s 825ms/step - loss: 1.5646 - accuracy: 0.3830 - val_loss: 1.4202 - val_accuracy: 0.4425\n",
      "Epoch 4/100\n",
      "226/226 [==============================] - 215s 951ms/step - loss: 1.4947 - accuracy: 0.4166 - val_loss: 1.4026 - val_accuracy: 0.4563\n",
      "Epoch 5/100\n",
      "226/226 [==============================] - 226s 1s/step - loss: 1.4581 - accuracy: 0.4348 - val_loss: 1.3516 - val_accuracy: 0.4785\n",
      "Epoch 6/100\n",
      "226/226 [==============================] - 242s 1s/step - loss: 1.4300 - accuracy: 0.4453 - val_loss: 1.3183 - val_accuracy: 0.4973\n",
      "Epoch 7/100\n",
      "226/226 [==============================] - 239s 1s/step - loss: 1.4055 - accuracy: 0.4579 - val_loss: 1.3092 - val_accuracy: 0.4942\n",
      "Epoch 8/100\n",
      "226/226 [==============================] - 237s 1s/step - loss: 1.3858 - accuracy: 0.4664 - val_loss: 1.2891 - val_accuracy: 0.5001\n",
      "Epoch 9/100\n",
      "226/226 [==============================] - 244s 1s/step - loss: 1.3589 - accuracy: 0.4759 - val_loss: 1.2495 - val_accuracy: 0.5153\n",
      "Epoch 10/100\n",
      "226/226 [==============================] - 241s 1s/step - loss: 1.3484 - accuracy: 0.4820 - val_loss: 1.2411 - val_accuracy: 0.5207\n",
      "Epoch 11/100\n",
      "226/226 [==============================] - 240s 1s/step - loss: 1.3294 - accuracy: 0.4899 - val_loss: 1.2116 - val_accuracy: 0.5299\n",
      "Epoch 12/100\n",
      "226/226 [==============================] - 237s 1s/step - loss: 1.3225 - accuracy: 0.4914 - val_loss: 1.2242 - val_accuracy: 0.5249\n",
      "Epoch 13/100\n",
      "226/226 [==============================] - 238s 1s/step - loss: 1.3059 - accuracy: 0.4990 - val_loss: 1.2068 - val_accuracy: 0.5340\n",
      "Epoch 14/100\n",
      "226/226 [==============================] - 205s 908ms/step - loss: 1.2995 - accuracy: 0.5021 - val_loss: 1.2214 - val_accuracy: 0.5355\n",
      "Epoch 15/100\n",
      "226/226 [==============================] - 217s 960ms/step - loss: 1.2808 - accuracy: 0.5121 - val_loss: 1.1868 - val_accuracy: 0.5444\n",
      "Epoch 16/100\n",
      "226/226 [==============================] - 227s 1s/step - loss: 1.2790 - accuracy: 0.5164 - val_loss: 1.1725 - val_accuracy: 0.5514\n",
      "Epoch 17/100\n",
      "226/226 [==============================] - 244s 1s/step - loss: 1.2694 - accuracy: 0.5148 - val_loss: 1.1806 - val_accuracy: 0.5555\n",
      "Epoch 18/100\n",
      "226/226 [==============================] - 257s 1s/step - loss: 1.2626 - accuracy: 0.5208 - val_loss: 1.1600 - val_accuracy: 0.5579\n",
      "Epoch 19/100\n",
      "226/226 [==============================] - 264s 1s/step - loss: 1.2600 - accuracy: 0.5183 - val_loss: 1.1691 - val_accuracy: 0.5553\n",
      "Epoch 20/100\n",
      "226/226 [==============================] - 247s 1s/step - loss: 1.2475 - accuracy: 0.5251 - val_loss: 1.1454 - val_accuracy: 0.5601\n",
      "Epoch 21/100\n",
      "226/226 [==============================] - 218s 964ms/step - loss: 1.2502 - accuracy: 0.5236 - val_loss: 1.1601 - val_accuracy: 0.5616\n",
      "Epoch 22/100\n",
      "226/226 [==============================] - 217s 960ms/step - loss: 1.2375 - accuracy: 0.5277 - val_loss: 1.1442 - val_accuracy: 0.5651\n",
      "Epoch 23/100\n",
      "226/226 [==============================] - 306s 1s/step - loss: 1.2398 - accuracy: 0.5291 - val_loss: 1.1422 - val_accuracy: 0.5723\n",
      "Epoch 24/100\n",
      "226/226 [==============================] - 221s 976ms/step - loss: 1.2259 - accuracy: 0.5297 - val_loss: 1.1308 - val_accuracy: 0.5701\n",
      "Epoch 25/100\n",
      "226/226 [==============================] - 220s 972ms/step - loss: 1.2288 - accuracy: 0.5315 - val_loss: 1.1260 - val_accuracy: 0.5736\n",
      "Epoch 26/100\n",
      "226/226 [==============================] - 221s 977ms/step - loss: 1.2152 - accuracy: 0.5370 - val_loss: 1.1432 - val_accuracy: 0.5668\n",
      "Epoch 27/100\n",
      "226/226 [==============================] - 222s 983ms/step - loss: 1.2101 - accuracy: 0.5402 - val_loss: 1.1352 - val_accuracy: 0.5722\n",
      "Epoch 28/100\n",
      "226/226 [==============================] - 219s 969ms/step - loss: 1.2146 - accuracy: 0.5401 - val_loss: 1.1229 - val_accuracy: 0.5757\n",
      "Epoch 29/100\n",
      "226/226 [==============================] - 219s 967ms/step - loss: 1.2016 - accuracy: 0.5418 - val_loss: 1.1255 - val_accuracy: 0.5767\n",
      "Epoch 30/100\n",
      "226/226 [==============================] - 218s 964ms/step - loss: 1.1948 - accuracy: 0.5442 - val_loss: 1.1212 - val_accuracy: 0.5698\n",
      "Epoch 31/100\n",
      "226/226 [==============================] - 221s 976ms/step - loss: 1.1987 - accuracy: 0.5430 - val_loss: 1.1192 - val_accuracy: 0.5787\n",
      "Epoch 32/100\n",
      "226/226 [==============================] - 219s 967ms/step - loss: 1.1951 - accuracy: 0.5479 - val_loss: 1.1027 - val_accuracy: 0.5812\n",
      "Epoch 33/100\n",
      "226/226 [==============================] - 218s 965ms/step - loss: 1.1835 - accuracy: 0.5497 - val_loss: 1.1144 - val_accuracy: 0.5783\n",
      "Epoch 34/100\n",
      "226/226 [==============================] - 221s 978ms/step - loss: 1.1795 - accuracy: 0.5517 - val_loss: 1.1085 - val_accuracy: 0.5794\n",
      "Epoch 35/100\n",
      "226/226 [==============================] - 219s 969ms/step - loss: 1.1790 - accuracy: 0.5554 - val_loss: 1.1197 - val_accuracy: 0.5778\n",
      "Epoch 36/100\n",
      "226/226 [==============================] - 225s 994ms/step - loss: 1.1827 - accuracy: 0.5511 - val_loss: 1.1340 - val_accuracy: 0.5702\n",
      "Epoch 37/100\n",
      "226/226 [==============================] - 224s 992ms/step - loss: 1.1689 - accuracy: 0.5561 - val_loss: 1.1049 - val_accuracy: 0.5875\n",
      "Epoch 38/100\n",
      "226/226 [==============================] - 219s 970ms/step - loss: 1.1656 - accuracy: 0.5575 - val_loss: 1.0946 - val_accuracy: 0.5893\n",
      "Epoch 39/100\n",
      "226/226 [==============================] - 221s 978ms/step - loss: 1.1689 - accuracy: 0.5594 - val_loss: 1.1030 - val_accuracy: 0.5870\n",
      "Epoch 40/100\n",
      "226/226 [==============================] - 220s 972ms/step - loss: 1.1656 - accuracy: 0.5562 - val_loss: 1.0931 - val_accuracy: 0.5889\n",
      "Epoch 41/100\n",
      "226/226 [==============================] - 218s 967ms/step - loss: 1.1600 - accuracy: 0.5623 - val_loss: 1.0954 - val_accuracy: 0.5873\n",
      "Epoch 42/100\n",
      " 59/226 [======>.......................] - ETA: 2:38 - loss: 1.1373 - accuracy: 0.5649"
     ]
    }
   ],
   "source": [
    "model.fit(x = x_train,y=y_train,batch_size=128,epochs=100,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd9fff-f767-4a27-b56b-18a03008d9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
